<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>The Measure and Mismeasure of Fairness</title>
    <link rel="stylesheet" href="/assets/css/styles.css?v=3">

    <!-- Add MathJax Latex Support -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Add Custom Javascript -->
    

    <link type="application/atom+xml" rel="alternate" href="https://www.jgaeb.com/feed.xml" title="Jgaeb" />

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The Measure and Mismeasure of Fairness | Jgaeb</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="The Measure and Mismeasure of Fairness" />
<meta name="author" content="Sam Corbett-Davies\*" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The field of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last decade, several formal, mathematical definitions of fairness have gained prominence. Here we first assemble and categorize these definitions into two broad families: (1) those that constrain the effects of decisions on disparities; and (2) those that constrain the effects of legally protected characteristics, like race and gender, on decisions. We then show, analytically and empirically, that both families of definitions typically result in strongly Pareto dominated decision policies. For example, in the case of college admissions, adhering to popular formal conceptions of fairness would simultaneously result in lower student-body diversity and a less academically prepared class, relative to what one could achieve by explicitly tailoring admissions policies to achieve desired outcomes. In this sense, requiring that these fairness definitions hold can, perversely, harm the very groups they were designed to protect. In contrast to axiomatic notions of fairness, we argue that the equitable design of algorithms requires grappling with their context-specific consequences, akin to the equitable design of policy. We conclude by listing several open challenges in fair machine learning and offering strategies to ensure algorithms are better aligned with policy goals." />
<meta property="og:description" content="The field of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last decade, several formal, mathematical definitions of fairness have gained prominence. Here we first assemble and categorize these definitions into two broad families: (1) those that constrain the effects of decisions on disparities; and (2) those that constrain the effects of legally protected characteristics, like race and gender, on decisions. We then show, analytically and empirically, that both families of definitions typically result in strongly Pareto dominated decision policies. For example, in the case of college admissions, adhering to popular formal conceptions of fairness would simultaneously result in lower student-body diversity and a less academically prepared class, relative to what one could achieve by explicitly tailoring admissions policies to achieve desired outcomes. In this sense, requiring that these fairness definitions hold can, perversely, harm the very groups they were designed to protect. In contrast to axiomatic notions of fairness, we argue that the equitable design of algorithms requires grappling with their context-specific consequences, akin to the equitable design of policy. We conclude by listing several open challenges in fair machine learning and offering strategies to ensure algorithms are better aligned with policy goals." />
<link rel="canonical" href="https://www.jgaeb.com/papers/measure-mismeasure.html" />
<meta property="og:url" content="https://www.jgaeb.com/papers/measure-mismeasure.html" />
<meta property="og:site_name" content="Jgaeb" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-08-19T22:11:34+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Measure and Mismeasure of Fairness" />
<meta name="twitter:site" content="@jgaeb1" />
<meta name="twitter:creator" content="@Sam Corbett-Davies\*" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Sam Corbett-Davies\\*"},"dateModified":"2025-08-19T22:11:34+00:00","datePublished":"2025-08-19T22:11:34+00:00","description":"The field of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last decade, several formal, mathematical definitions of fairness have gained prominence. Here we first assemble and categorize these definitions into two broad families: (1) those that constrain the effects of decisions on disparities; and (2) those that constrain the effects of legally protected characteristics, like race and gender, on decisions. We then show, analytically and empirically, that both families of definitions typically result in strongly Pareto dominated decision policies. For example, in the case of college admissions, adhering to popular formal conceptions of fairness would simultaneously result in lower student-body diversity and a less academically prepared class, relative to what one could achieve by explicitly tailoring admissions policies to achieve desired outcomes. In this sense, requiring that these fairness definitions hold can, perversely, harm the very groups they were designed to protect. In contrast to axiomatic notions of fairness, we argue that the equitable design of algorithms requires grappling with their context-specific consequences, akin to the equitable design of policy. We conclude by listing several open challenges in fair machine learning and offering strategies to ensure algorithms are better aligned with policy goals.","headline":"The Measure and Mismeasure of Fairness","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.jgaeb.com/papers/measure-mismeasure.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://www.jgaeb.com/assets/img/headshot.png"},"name":"Sam Corbett-Davies\\*"},"url":"https://www.jgaeb.com/papers/measure-mismeasure.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <header>
      <h1>Johann D. Gaebler</h1>
      <p class="contact-info"><a href="mailto:me@jgaeb.com">Email</a> • <a href="https://github.com/jgaeb">GitHub</a> • <a href="https://twitter.com/jgaeb1">Twitter</a></contact>
    </header>
    <nav>
      <div class="wrapper-nav-items">

  <div class="nav-item-container">
    <a href="/" >
      Home
    </a>
  </div>

  <div class="nav-item-container">
    <a href="/about.html" >
      About
    </a>
  </div>

  <div class="nav-item-container">
    <a href="/research.html" >
      Research
    </a>
  </div>

  <div class="nav-item-container">
    <a href="/blog.html" >
      Blog
    </a>
  </div>

</div>

    </nav>
    <main>
      <article class="paper">
  <section>
    <h1>The Measure and Mismeasure of Fairness</h1>
    <p class="authors">Sam Corbett-Davies*, Johann D. Gaebler*, Hamed Nilforoshan*, Ravi Shroff, and Sharad Goel</p>
    <p class="biblio">
      <em>Journal of Machine Learning Research</em>,
      2023.
    </p>

    

    
    <p class="biblio">
      ArXiv: <a href="https://arxiv.org/abs/1808.00023">1808.00023</a>.
    </p>
    

    

    
    <p class="biblio">Replication materials: <a href="https://github.com/jgaeb/measure-mismeasure">https://github.com/jgaeb/measure-mismeasure</a>.</p>
    

    <h2>Abstract</h2>
    <p>The field of fair machine learning aims to ensure that decisions guided by
algorithms are equitable. Over the last decade, several formal, mathematical
definitions of fairness have gained prominence. Here we first assemble and
categorize these definitions into two broad families: (1) those that constrain
the effects of decisions on disparities; and (2) those that constrain the
effects of legally protected characteristics, like race and gender, on
decisions. We then show, analytically and empirically, that both families of
definitions typically result in strongly Pareto dominated decision policies.
For example, in the case of college admissions, adhering to popular formal
conceptions of fairness would simultaneously result in lower student-body
diversity and a less academically prepared class, relative to what one could
achieve by explicitly tailoring admissions policies to achieve desired
outcomes. In this sense, requiring that these fairness definitions hold can,
perversely, harm the very groups they were designed to protect. In contrast to
axiomatic notions of fairness, we argue that the equitable design of algorithms
requires grappling with their context-specific consequences, akin to the
equitable design of policy. We conclude by listing several open challenges in
fair machine learning and offering strategies to ensure algorithms are better
aligned with policy goals.</p>

  </section>

  <section>
    

    
    <h2>Related Posts</h2>
    <ul>
      
      <li><a href="/2023/11/04/measure-mismeasure.html">The Measure and Mismeasure of Fairness</a></li>
      
      <li><a href="/2022/07/18/prevalence.html">Slicing Infinity</a></li>
      
    </ul>
    
  </section>
</article>

    </main>
    <footer>
  
  <p>
    &copy; 2021–2025 Johann D. Gaebler.
    Last updated August 19, 2025.
  </p>
</footer>

  </body>
</html>
